{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ§  Pixels2Patterns: A Hands-On Workshop on Convolutional Neural Networks  \n",
        "### Organized by **NeuralHive**, PES University EC Campus  \n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Œ Introduction  \n",
        "Welcome to **Pixels2Patterns**, a hands-on workshop crafted to provide a **solid foundation in Convolutional Neural Networks (CNNs)** â€” the core architecture powering modern **computer vision**.  \n",
        "\n",
        "In this session, you will not only **learn the theory behind CNNs**, but also **implement and experiment** with them on a classic dataset, gaining practical, research-ready skills.  \n",
        "\n",
        "---\n",
        "\n",
        "## ðŸŽ¯ Workshop Objectives  \n",
        "By the end of this notebook, you will be able to:  \n",
        "- **Build** and train a **vanilla CNN** from scratch on the **MNIST handwritten digits dataset** âœï¸ðŸ”¢  \n",
        "- **Understand** the role of:  \n",
        "  - Convolutional Layers  \n",
        "  - Pooling Layers  \n",
        "  - Fully Connected Layers  \n",
        "  - Output Predictions  \n",
        "- **Experiment** with hyperparameters and architecture to see how small changes affect performance.  \n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ§ª Your Interactive Lab  \n",
        "This notebook serves as your **guided lab environment**:  \n",
        "- Follow along with the structured code examples.  \n",
        "- Modify the architecture, layers, or training parameters.  \n",
        "- Observe in real time how **pixels are transformed into patterns** that drive model intelligence.  \n",
        "\n",
        "---\n",
        "\n",
        "## ðŸš€ Why This Matters  \n",
        "CNNs form the **backbone of image classification, object detection, and recognition systems** used across industries â€” from **healthcare** and **autonomous vehicles** to **space research** and **security systems**.  \n",
        "This workshop equips you with the **core intuition and hands-on skills** to build upon, whether your next step is academic research or practical deployment.  \n",
        "\n",
        "---\n",
        "\n",
        "âœ¨ **Letâ€™s begin â€” where pixels evolve into patterns, and patterns into intelligence.**"
      ],
      "metadata": {
        "id": "iky0btfOm0ep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup & Imports\n",
        "\n",
        "In this section, we prepare the **PyTorch environment** for our CNN on the MNIST dataset.  \n",
        "\n",
        "We will:  \n",
        "- Import all necessary **libraries** for building, training, and visualizing the model.  \n",
        "- Set up **device configuration** to leverage GPU if available.  \n",
        "- Ensure **reproducibility** with random seeds.  \n",
        "- Define **helper functions** for visualizing MNIST images interactively.  \n",
        "\n",
        "> This forms the foundation of our hands-on lab, ensuring everything is ready before we start building the CNN."
      ],
      "metadata": {
        "id": "QGQro2uyyuqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "#             Setup & Imports\n",
        "# Pixels2Patterns Workshop | PyTorch MNIST CNN\n",
        "# ========================================\n",
        "\n",
        "import time  # For simulating step-by-step execution\n",
        "\n",
        "# --- Step 1: Core Libraries ---\n",
        "print(\"========================================\")\n",
        "print(\"STEP 1: Importing Core Libraries...\")\n",
        "import torch                             # PyTorch core: tensors, autograd, etc.\n",
        "import torch.nn as nn                    # Neural network modules: layers like Conv, Linear\n",
        "import torch.nn.functional as functions  # Activation functions like ReLU, Softmax\n",
        "import torch.optim as optimizers         # Optimizers: algorithms to update weights during training\n",
        "time.sleep(1)\n",
        "print(\"Core libraries imported!\\n\")\n",
        "\n",
        "# --- Step 2: Dataset Utilities ---\n",
        "print(\"STEP 2: Importing Dataset Utilities...\")\n",
        "from torchvision import datasets, transforms   # Prebuilt datasets and image transformations\n",
        "from torch.utils.data import DataLoader        # For batching and shuffling data\n",
        "time.sleep(1)\n",
        "print(\"Dataset utilities imported!\\n\")\n",
        "\n",
        "# --- Step 3: Visualization ---\n",
        "print(\"STEP 3: Importing Visualization Libraries...\")\n",
        "import matplotlib.pyplot as plt  # Plotting images, graphs, training curves\n",
        "import numpy as np               # Array and numerical operations\n",
        "time.sleep(1)\n",
        "print(\"Visualization libraries imported!\\n\")\n",
        "\n",
        "# --- Step 4: Device Setup ---\n",
        "print(\"STEP 4: Setting up Device (CPU/GPU)...\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Automatically use GPU if available\n",
        "time.sleep(1)\n",
        "print(f\"Device available: '{device}'!\\n\")\n",
        "\n",
        "# --- Step 5: Reproducibility ---\n",
        "print(\"STEP 5: Setting random seeds for reproducibility...\")\n",
        "torch.manual_seed(42)                    # Fix random seed for CPU\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)          # Fix random seed for GPU\n",
        "time.sleep(1)\n",
        "print(\"Random seeds set!\\n\")\n",
        "\n",
        "# --- Step 6: Helper Function ---\n",
        "print(\"STEP 6: Defining helper function to visualize images...\")\n",
        "\n",
        "def show_images(images, labels, n=6):\n",
        "    \"\"\"\n",
        "    Display the first 'n' images from a batch along with their labels.\n",
        "    Useful for quickly visualizing MNIST samples.\n",
        "    \"\"\"\n",
        "    images = images[:n]    # Take only first n images\n",
        "    labels = labels[:n]    # Corresponding labels\n",
        "\n",
        "    plt.figure(figsize=(12, 2))\n",
        "    for i in range(n):\n",
        "        plt.subplot(1, n, i+1)\n",
        "        plt.imshow(images[i].squeeze(), cmap='gray')  # MNIST images are grayscale\n",
        "        plt.title(f\"Label: {labels[i].item()}\")       # Show true label\n",
        "        plt.axis('off')                               # Hide axes for clarity\n",
        "    plt.show()\n",
        "\n",
        "time.sleep(1)\n",
        "print(\"Helper function 'show_images' ready!\\n\")\n",
        "\n",
        "print(\"Setup & Imports Complete. Ready to load the MNIST dataset! âœ…\")\n",
        "print(\"========================================\")"
      ],
      "metadata": {
        "id": "0ONWpAasnjJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cffd22c9-f804-481f-f951-a49377005a9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "STEP 1: Importing Core Libraries...\n",
            "Core libraries imported!\n",
            "\n",
            "STEP 2: Importing Dataset Utilities...\n",
            "Dataset utilities imported!\n",
            "\n",
            "STEP 3: Importing Visualization Libraries...\n",
            "Visualization libraries imported!\n",
            "\n",
            "STEP 4: Setting up Device (CPU/GPU)...\n",
            "Device available: 'cuda'!\n",
            "\n",
            "STEP 5: Setting random seeds for reproducibility...\n",
            "Random seeds set!\n",
            "\n",
            "STEP 6: Defining helper function to visualize images...\n",
            "Helper function 'show_images' ready!\n",
            "\n",
            "Setup & Imports Complete. Ready to load the MNIST dataset! âœ…\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "#    Dataset Loading & Visualization\n",
        "# Pixels2Patterns Workshop | PyTorch MNIST CNN\n",
        "# ========================================\n",
        "\n",
        "import time  # For simulating step-by-step execution\n",
        "\n",
        "print(\"========================================\")\n",
        "print(\"STEP 1: Defining Transformations for MNIST...\")\n",
        "# --- Transform: convert images to tensors and normalize pixel values ---\n",
        "# MNIST images are 28x28 grayscale images with pixel values 0-255.\n",
        "# transforms.ToTensor() converts them to [0,1] float tensors.\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "time.sleep(1)\n",
        "print(\"Transformations defined.\\n\")\n",
        "\n",
        "print(\"STEP 2: Loading MNIST Dataset...\")\n",
        "# --- Load MNIST training and test datasets ---\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset  = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "time.sleep(1)\n",
        "print(f\"Training samples: {len(train_dataset)}, Test samples: {len(test_dataset)}\\n\")\n",
        "\n",
        "print(\"STEP 3: Creating DataLoaders for batching...\")\n",
        "# --- DataLoader: batching and shuffling ---\n",
        "# Batch size = 64 means we process 64 images at a time.\n",
        "# shuffle=True ensures training data is randomly ordered for each epoch.\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "time.sleep(1)\n",
        "print(\"DataLoaders ready.\\n\")\n",
        "\n",
        "print(\"STEP 4: Defining helper function to visualize images...\")\n",
        "def show_images(images, labels, n=6):\n",
        "    \"\"\"\n",
        "    Display the first 'n' images from a batch along with their labels.\n",
        "    Helps in understanding what the model will see during training.\n",
        "    \"\"\"\n",
        "    images = images[:n]\n",
        "    labels = labels[:n]\n",
        "\n",
        "    plt.figure(figsize=(12, 2))\n",
        "    for i in range(n):\n",
        "        plt.subplot(1, n, i+1)\n",
        "        plt.imshow(images[i].squeeze(), cmap='gray')  # MNIST images are grayscale\n",
        "        plt.title(f\"Label: {labels[i].item()}\")       # Show the true label\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "time.sleep(1)\n",
        "print(\"Helper function 'show_images' ready.\\n\")\n",
        "\n",
        "print(\"STEP 5: Displaying a few training samples to explore the dataset...\")\n",
        "# --- Take one batch of training images and visualize ---\n",
        "examples = next(iter(train_loader))\n",
        "images, labels = examples\n",
        "show_images(images, labels)\n",
        "time.sleep(1)\n",
        "print(\"Sample images displayed. Dataset overview complete.\")\n",
        "print(\"========================================\\n\")\n"
      ],
      "metadata": {
        "id": "bYGxsDiKycU9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "outputId": "5ddc43ce-ff6a-4a73-ca66-a7a7b19cb678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========================================\n",
            "STEP 1: Defining Transformations for MNIST...\n",
            "Transformations defined.\n",
            "\n",
            "STEP 2: Loading MNIST Dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.91M/9.91M [00:00<00:00, 18.1MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.9k/28.9k [00:00<00:00, 494kB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65M/1.65M [00:00<00:00, 4.64MB/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.54k/4.54k [00:00<00:00, 12.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 60000, Test samples: 10000\n",
            "\n",
            "STEP 3: Creating DataLoaders for batching...\n",
            "DataLoaders ready.\n",
            "\n",
            "STEP 4: Defining helper function to visualize images...\n",
            "Helper function 'show_images' ready.\n",
            "\n",
            "STEP 5: Displaying a few training samples to explore the dataset...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x200 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample images displayed. Dataset overview complete.\n",
            "========================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNNModel Architecture (Sequential Style)\n",
        "\n",
        "In this section, we define a **Convolutional Neural Network using `nn.Sequential`**, which simplifies stacking layers and makes the forward pass clean and readable.\n",
        "\n",
        "---\n",
        "\n",
        "### **Architecture Overview**\n",
        "\n",
        "1. **Convolutional Layers**\n",
        "   - **Conv1:** 1 input channel â†’ 32 output channels, 3x3 kernel, stride=1, padding=1  \n",
        "     Learns **basic edges** from grayscale images.\n",
        "   - **Conv2:** 32 â†’ 64 channels, 2x2 kernel, stride=2, padding=2  \n",
        "     Reduces spatial size roughly by half and learns **higher-level patterns**.\n",
        "   - **Conv3:** 64 â†’ 64 channels, 2x2 kernel, stride=1, padding=1  \n",
        "     Further extracts features before pooling.  \n",
        "   - **ReLU activations** after each conv layer introduce **non-linearity**.\n",
        "\n",
        "2. **Pooling**\n",
        "   - **MaxPool2d(2,2):** Reduces width and height by 2, keeping the most important features.\n",
        "\n",
        "3. **Flattening**\n",
        "   - Converts 3D feature maps into a 1D vector for the fully connected layers.\n",
        "\n",
        "4. **Fully Connected Layers**\n",
        "   - **Linear(4096 â†’ 1024) + ReLU:** Combines features into higher-level representations.\n",
        "   - **Linear(1024 â†’ 10):** Output layer representing **digits 0â€“9**.\n",
        "\n",
        "5. **Output**\n",
        "   - Produces **logits** for each class.  \n",
        "   - Softmax is applied internally by `CrossEntropyLoss` during training.\n",
        "\n",
        "---\n",
        "\n",
        "### **Playground / Experiments**\n",
        "- Change **number of filters** (e.g., Conv1: 32 â†’ 64)  \n",
        "- Modify **kernel sizes** (e.g., 3x3 â†’ 5x5) or **strides**  \n",
        "- Adjust **fully connected layer sizes** (e.g., 4096 â†’ 2048)  \n",
        "- Add **Dropout layers** to reduce overfitting  \n",
        "- Visualize **feature maps** after convolutional layers to see what the network is learning  \n",
        "\n",
        "---\n",
        "\n",
        "âœ… This architecture is slightly deeper than our basic CNN and is designed to **learn MNIST digits efficiently** while giving students opportunities to experiment and explore.\n"
      ],
      "metadata": {
        "id": "wewXSrsw2XXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "#          CNNModel Architecture\n",
        "# ========================================\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "print(\"STEP 1: Defining CNNModel using nn.Sequential...\")\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # Using nn.Sequential to stack layers\n",
        "        self.stack = nn.Sequential(\n",
        "\n",
        "            # --- Convolution Layer 1 ---\n",
        "            # Input: 1 channel (grayscale), Output: 32 channels\n",
        "            # Kernel: 3x3, stride=1, padding=1 keeps 28x28 size\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),  # Non-linearity\n",
        "\n",
        "            # --- Convolution Layer 2 ---\n",
        "            # Input: 32, Output: 64, Kernel: 2x2, stride=2, padding=2\n",
        "            # Stride=2 reduces spatial size roughly by half\n",
        "            nn.Conv2d(32, 64, kernel_size=2, stride=2, padding=2),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # --- Convolution Layer 3 ---\n",
        "            # Input: 64, Output: 64, Kernel: 2x2, stride=1, padding=1\n",
        "            nn.Conv2d(64, 64, kernel_size=2, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # --- Max Pooling ---\n",
        "            # Reduces width and height by factor of 2\n",
        "            nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # --- Flatten ---\n",
        "            nn.Flatten(),\n",
        "\n",
        "            # --- Fully Connected Layers ---\n",
        "            # First FC: 4096 â†’ 1024 neurons, ReLU non-linearity\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            # Output layer: 1024 â†’ 10 (digits 0-9)\n",
        "            nn.Linear(1024, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, xb):\n",
        "        # Forward pass through the stacked layers\n",
        "        out = self.stack(xb)\n",
        "        return out\n",
        "\n",
        "# Instantiate model and move to GPU/CPU\n",
        "model = CNNModel().to(device)\n",
        "print(\"\\nCNNModel defined successfully!\")\n",
        "print(model)"
      ],
      "metadata": {
        "id": "s9aJ1yvb2YQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f47136a-6aa2-4d1d-a026-c98aeb072f65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 1: Defining CNNModel using nn.Sequential...\n",
            "\n",
            "CNNModel defined successfully!\n",
            "CNNModel(\n",
            "  (stack): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
            "    (5): ReLU()\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Flatten(start_dim=1, end_dim=-1)\n",
            "    (8): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (9): ReLU()\n",
            "    (10): Linear(in_features=1024, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Loss Function & Optimizer\n",
        "\n",
        "In this section, we set up the **loss function** and **optimizer** required to train our `CNNModel`.\n",
        "\n",
        "---\n",
        "\n",
        "### **Loss Function**\n",
        "\n",
        "- We use **CrossEntropyLoss** for multi-class classification (digits 0â€“9).  \n",
        "- It combines **softmax** and **negative log-likelihood**, so we donâ€™t need to apply softmax in the network.  \n",
        "- Measures **how far the predicted logits are from the true labels**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Optimizer**\n",
        "\n",
        "- We use **Adam optimizer**, which adapts learning rates for each parameter automatically.  \n",
        "- Optimizer updates network weights based on **gradients computed via backpropagation**.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Playground / Experiments**\n",
        "\n",
        "- Try different optimizers: `SGD`, `RMSprop`  \n",
        "- Adjust learning rate (`lr`) to see faster or slower convergence  \n",
        "- Experiment with **momentum** when using SGD  \n",
        "- Observe **how loss decreases** with different settings  \n",
        "\n",
        "---\n",
        "\n",
        "âœ… With the loss function and optimizer defined, our CNNModel is now ready for **training**.\n"
      ],
      "metadata": {
        "id": "A8Eeynn16g-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "#    Define Loss Function & Optimizer\n",
        "# ========================================\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optimizers  # Already imported earlier\n",
        "\n",
        "print(\"STEP 2: Setting up Loss Function and Optimizer for CNNModel...\")\n",
        "\n",
        "# --- 1. Loss Function ---\n",
        "# For multi-class classification (digits 0-9), CrossEntropyLoss is ideal.\n",
        "# ðŸ”¹ Combines softmax + negative log-likelihood internally\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "print(\"âœ… Loss function: CrossEntropyLoss set successfully.\")\n",
        "\n",
        "# --- 2. Optimizer ---\n",
        "# Adam is a popular optimizer that adapts learning rates for each parameter\n",
        "learning_rate = 0.001\n",
        "optimizer = optimizers.Adam(model.parameters(), lr=learning_rate)\n",
        "print(f\"âœ… Optimizer: Adam with learning rate = {learning_rate} set successfully.\")\n",
        "\n",
        "# --- Optional experiments for students ---\n",
        "# optimizer = optimizers.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "# optimizer = optimizers.RMSprop(model.parameters(), lr=0.001)\n",
        "# learning_rate = 0.005\n",
        "\n",
        "print(\"\\nLoss and Optimizer are ready. The CNNModel can now be trained!\")"
      ],
      "metadata": {
        "id": "_gHFyQbs6hmf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e80e2dd5-6388-4189-d738-8c3ce673560a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STEP 2: Setting up Loss Function and Optimizer for CNNModel...\n",
            "âœ… Loss function: CrossEntropyLoss set successfully.\n",
            "âœ… Optimizer: Adam with learning rate = 0.001 set successfully.\n",
            "\n",
            "Loss and Optimizer are ready. The CNNModel can now be trained!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop for CNNModel\n",
        "\n",
        "In this section, we train our `CNNModel` on the MNIST dataset using the **defined loss function** and **optimizer**. The loop runs over multiple epochs, performing forward and backward passes, and updates the model's weights.\n",
        "\n",
        "---\n",
        "\n",
        "### **Step-by-Step Explanation**\n",
        "\n",
        "1. **Hyperparameters**\n",
        "   - `num_epochs`: Number of times the model sees the entire dataset.  \n",
        "   - `batch_size`: Number of samples processed at once.  \n",
        "   - `learning_rate`: Step size for optimizer updates.  \n",
        "\n",
        "2. **Training Steps**\n",
        "   - **Set model to training mode** with `model.train()`. Important for layers like Dropout or BatchNorm.  \n",
        "   - **Forward pass**: Feed batch images to the model to get predictions.  \n",
        "   - **Compute loss**: Compare predictions with true labels using `CrossEntropyLoss`.  \n",
        "   - **Backward pass**: `loss.backward()` computes gradients for all parameters.  \n",
        "   - **Update weights**: `optimizer.step()` applies the gradient updates.  \n",
        "   - **Zero gradients**: `optimizer.zero_grad()` clears old gradients before the next step.  \n",
        "\n",
        "3. **Logging**\n",
        "   - Tracks **average loss per epoch**.  \n",
        "   - Optional: log batch-level loss to observe learning dynamics.\n",
        "\n",
        "---\n",
        "\n",
        "### **Student Playground / Experiments**\n",
        "\n",
        "- Change **num_epochs** to train longer or shorter.  \n",
        "- Adjust **batch_size** to see impact on training speed and stability.  \n",
        "- Modify **learning_rate** to observe faster or slower convergence.  \n",
        "- Uncomment batch-level logging to watch **loss per batch**.  \n",
        "- Experiment with **different optimizers** (SGD, RMSprop) and observe results.  \n",
        "\n",
        "---\n",
        "\n",
        "âœ… This loop lets students **see the model learn over time**, providing a hands-on understanding of **forward pass, loss computation, backpropagation, and weight updates**."
      ],
      "metadata": {
        "id": "QpAS0ZoiBpjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "#       Training Loop for CNNModel\n",
        "# ========================================\n",
        "\n",
        "import time\n",
        "\n",
        "# --- Hyperparameters ---\n",
        "num_epochs = 10         # Try 5, 10, 20, etc.\n",
        "batch_size = 64         # Try experimenting with 32, 128, etc.\n",
        "learning_rate = 0.001   # Already set in optimizer; can tweak for faster/slower learning\n",
        "\n",
        "# --- Load Data (if not already loaded) ---\n",
        "# Using the same MNIST train_loader and test_loader from earlier\n",
        "\n",
        "# --- Model, Loss, Optimizer (already defined) ---\n",
        "# model -> CNNModel\n",
        "# criterion -> CrossEntropyLoss\n",
        "# optimizer -> Adam\n",
        "\n",
        "print(\"ðŸš€ Starting Training...\\n\")\n",
        "\n",
        "# Track training loss per epoch\n",
        "train_losses = []\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    epoch_loss = 0.0\n",
        "    start_time = time.time()\n",
        "\n",
        "    model.train()  # Set model to training mode\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()          # Reset gradients\n",
        "\n",
        "        outputs = model(images)        # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "\n",
        "        loss.backward()                # Backpropagation\n",
        "        optimizer.step()               # Update weights\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        # --- Optional: Print batch loss for debugging ---\n",
        "        # if batch_idx % 100 == 0:\n",
        "        #     print(f\"Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "    train_losses.append(avg_loss)\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(f\"Epoch [{epoch}/{num_epochs}] - Loss: {avg_loss:.4f} - Time: {end_time - start_time:.1f}s\")\n",
        "\n",
        "print(\"\\nâœ… Training Complete!\")"
      ],
      "metadata": {
        "id": "G2kDjJArBqss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c97cac84-1e7a-4e45-fe13-ee0b8ee38020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Starting Training...\n",
            "\n",
            "Epoch [1/10] - Loss: 0.1558 - Time: 12.0s\n",
            "Epoch [2/10] - Loss: 0.0419 - Time: 10.6s\n",
            "Epoch [3/10] - Loss: 0.0260 - Time: 10.5s\n",
            "Epoch [4/10] - Loss: 0.0174 - Time: 10.5s\n",
            "Epoch [5/10] - Loss: 0.0128 - Time: 10.6s\n",
            "Epoch [6/10] - Loss: 0.0119 - Time: 10.2s\n",
            "Epoch [7/10] - Loss: 0.0087 - Time: 10.3s\n",
            "Epoch [8/10] - Loss: 0.0083 - Time: 10.5s\n",
            "Epoch [9/10] - Loss: 0.0065 - Time: 10.4s\n",
            "Epoch [10/10] - Loss: 0.0057 - Time: 10.5s\n",
            "\n",
            "âœ… Training Complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation on Test Set\n",
        "\n",
        "In this section, we evaluate our trained `CNNModel` on the **MNIST test set** to measure its performance and visualize predictions.\n",
        "\n",
        "---\n",
        "\n",
        "### **Evaluation Steps**\n",
        "\n",
        "1. **Set model to evaluation mode**  \n",
        "   - `model.eval()` disables Dropout and BatchNorm updates to ensure consistent predictions.  \n",
        "\n",
        "2. **Disable gradients**  \n",
        "   - `torch.no_grad()` prevents gradient computation, saving memory and speeding up evaluation.  \n",
        "\n",
        "3. **Compute Accuracy**  \n",
        "   - Compare the predicted class with true labels.  \n",
        "   - Accuracy = `(correct predictions / total samples) * 100`.  \n",
        "\n",
        "4. **Visualize Sample Predictions**  \n",
        "   - Display a few images along with **True labels (T)** and **Predicted labels (P)**.  \n",
        "   - Students can adjust the number of samples displayed (`n`) to explore more results.  \n",
        "\n",
        "---\n",
        "\n",
        "### **Student Playground / Experiments**\n",
        "\n",
        "- Display **misclassified images** to analyze where the model fails.  \n",
        "- Compare **train vs test accuracy** to detect overfitting.  \n",
        "- Experiment with **different architectures or hyperparameters** and observe changes in accuracy.  \n",
        "- Track predictions after adding **Dropout, BatchNorm, or changing activation functions**.  \n",
        "\n",
        "---\n",
        "\n",
        "âœ… This section lets students **quantitatively and visually assess** how well the CNNModel is performing on unseen data.\n",
        "`"
      ],
      "metadata": {
        "id": "9qNNMy4HCapA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "#     Model Evaluation on Test Set\n",
        "# ========================================\n",
        "\n",
        "print(\"ðŸ”Ž Evaluating CNNModel on Test Set...\")\n",
        "\n",
        "model.eval()  # Set model to evaluation mode (disables dropout, etc.)\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Disable gradient computation for evaluation (saves memory & speeds up)\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)               # Forward pass\n",
        "        _, predicted = torch.max(outputs, 1) # Get class with highest logit\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"âœ… Test Accuracy: {accuracy:.2f}%\\n\")\n",
        "\n",
        "# --- Display Sample Predictions ---\n",
        "examples = iter(test_loader)\n",
        "images, labels = next(examples)\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "outputs = model(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "# Move images to CPU for visualization\n",
        "images = images.cpu()\n",
        "labels = labels.cpu()\n",
        "predicted = predicted.cpu()\n",
        "\n",
        "# Display first 6 sample predictions\n",
        "def show_predictions(images, labels, preds, n=6):\n",
        "    plt.figure(figsize=(12, 2))\n",
        "    for i in range(n):\n",
        "        plt.subplot(1, n, i+1)\n",
        "        plt.imshow(images[i].squeeze(), cmap='gray')\n",
        "        plt.title(f\"T: {labels[i].item()} | P: {preds[i].item()}\")\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "show_predictions(images, labels, predicted)"
      ],
      "metadata": {
        "id": "zNyOLMpZCbBU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "364d003b-55f6-41a1-a6d8-acc8cfd38c54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”Ž Evaluating CNNModel on Test Set...\n",
            "âœ… Test Accuracy: 99.00%\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x200 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizations: Training Loss & Feature Maps\n",
        "\n",
        "In this section, we visualize the **training process** and explore the **feature maps learned by the CNN**.\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Training Loss Curve**\n",
        "\n",
        "- Plots **training loss vs epochs**.  \n",
        "- Helps students **see how the network converges over time**.  \n",
        "- Playground ideas:\n",
        "  - Change `num_epochs` to train longer or shorter.  \n",
        "  - Adjust learning rate or optimizer and observe changes in the curve.  \n",
        "  - Compare curves for different architectures.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Feature Map Visualization**\n",
        "\n",
        "- Visualizes the **activations from convolutional layers**.  \n",
        "- Each feature map shows **what patterns the network is detecting** in the input images.  \n",
        "- Students can experiment with:\n",
        "  - `layer_idx` to view different convolutional layers.  \n",
        "  - `n_features` to display more or fewer feature maps.  \n",
        "  - Input different digits to see how activations change.\n",
        "\n",
        "---\n",
        "\n",
        "### **Why it matters**\n",
        "\n",
        "- Connects **theory (convolutions, activations)** with **what the network actually sees**.  \n",
        "- Encourages students to **explore and understand CNN internals**, not just outputs.\n",
        "\n",
        "---\n",
        "\n",
        "âœ… These visualizations make the notebook **interactive and exploratory**, allowing students to **see learning dynamics** and **inspect intermediate representations** in the network."
      ],
      "metadata": {
        "id": "hXFC3hAMC8sU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================================\n",
        "# 8ï¸âƒ£ Visualizations: Training Loss & Feature Maps\n",
        "# ========================================\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- 1. Plot Training Loss Curve ---\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(train_losses, marker='o', color='blue')  # Plot loss recorded during training\n",
        "plt.title(\"Training Loss over Epochs\")            # Title of the plot\n",
        "plt.xlabel(\"Epoch\")                               # X-axis: epoch number\n",
        "plt.ylabel(\"Loss\")                                # Y-axis: loss value\n",
        "plt.grid(True)                                    # Add grid for better readability\n",
        "plt.show()                                        # Display the plot\n",
        "\n",
        "# --- 2. Optional: Visualize Feature Maps from First Conv Layer ---\n",
        "def visualize_feature_maps(model, images, layer_idx=0, n_features=6):\n",
        "    \"\"\"\n",
        "    Visualizes the first 'n_features' feature maps from a given convolutional layer.\n",
        "\n",
        "    Parameters:\n",
        "    - model: trained CNN model\n",
        "    - images: input images (batch) to pass through the network\n",
        "    - layer_idx: index of the layer in model.stack to visualize\n",
        "    - n_features: number of feature maps to display\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    with torch.no_grad():  # Disable gradient computation for visualization\n",
        "        x = images.to(device)  # Move input images to device (CPU/GPU)\n",
        "\n",
        "        # Pass the input through layers sequentially up to the selected layer\n",
        "        for i, layer in enumerate(model.stack):\n",
        "            x = layer(x)\n",
        "            if i == layer_idx:  # Stop at the desired layer\n",
        "                break\n",
        "\n",
        "        feature_maps = x.cpu()  # Move feature maps to CPU for plotting\n",
        "\n",
        "        # Plot the first 'n_features' feature maps\n",
        "        plt.figure(figsize=(12,2))\n",
        "        for i in range(min(n_features, feature_maps.shape[1])):\n",
        "            plt.subplot(1, n_features, i+1)\n",
        "            plt.imshow(feature_maps[0,i,:,:], cmap='viridis')  # Visualize single feature map\n",
        "            plt.title(f\"Feature {i+1}\")\n",
        "            plt.axis('off')  # Hide axes for cleaner visualization\n",
        "        plt.show()\n",
        "\n",
        "# --- Example Usage ---\n",
        "examples = iter(test_loader)\n",
        "images, labels = next(examples)                 # Get a batch of test images\n",
        "visualize_feature_maps(model, images, layer_idx=1, n_features=6)  # Visualize feature maps"
      ],
      "metadata": {
        "id": "oji2GeN6DXIU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}